# 系统的结构和系统调用



没错，第一章下来就是第三章，中间没有第二章....我找到的课就是这样的....





## isolation 隔离性

所谓隔离性，就是要求软件和软件之间相互隔离，比如你的系统上同时运行着qq和微信，不能因为qq的崩溃而导致微信也跟着崩了；

如果qq和微信都直接运行在硬件上，那么他们之间就没有隔离，如此一来可能出现这样的问题：

qq先在0x11111111这个内存上放了一段话，但是微信并不知道，微信也在0x11111111这个地址的内存上放了一段话，那么此时，qq从0x11111111这个内存地址上再读出来的数据就不是它原先放进去的那段了；

当然实际情况可能更糟糕，被别的软件随意修改内存很大的概率会造成软件的崩溃；

我们的操作系统必须保证上述的情况不会发生，即，操作系统必须保证隔离性；

隔离性的核心是“多路复用 multiplexing” 与 “内存隔离”

实现这两个要求的途径是“抽象硬件资源”；

举个例子：

当我们使用fork的时候，会创建一个进程，虽然进程上跑的 应用程序 最终一定会交给CPU处理，但是进程本身又不是CPU；某种程度上**进程**就是对CPU的一种抽象；

类似的：

| 概念    | 对应的硬件功能 |
| ------- | -------------- |
| process | CPU            |
| exec    | 内存           |
| files   | 硬盘           |
| ...     | ...            |



在做系统相关的编程的时候，有一个概念叫做“防御性”； 你的代码应该具有防御性，不能因为应用软件的行为导致系统的崩溃；尽管来自软件的“攻击”可能是有意为之，也可能只是无心之举；

为了能够实现强隔离，我们需要硬件上的支持，如果你曾经学过微机原理，那么或许你对X86系列的处理器所提供的“实模式”，“保护模式”有一些认识，RISCV同样提供了类似的功能--“user\kernel mode”和“virtual mode”；实际上这种模式在几乎所有架构的CPU中都被广泛的使用...X86，arm，risc-v，都是这样运作的；



## 内核模式 kernel mode 与用户模式 user mode

### user/kernel mode

user mode: CPU只能执行unprivileged instruction（非特权指令）

kernel mode: cpu可以执行privileged instruction（特权指令）

所谓unprivileged instruction，例如：ADD，SUB，如果你有学过微机原理，那么你应该知道这两条指令的语义，这类操作属于任何一个软件都能使用的操作；

而privilege instruction，例如关闭时钟中断，设置page table寄存器等，这些操作是实打实的会对硬件产生作用的操作，因此不能让路边的阿猫阿狗随便去用；

**一般的处理器会通过一个flag来标志，当前CPU处于user mode还是kernel mode**



### 虚拟内存与页表

（虚拟内存有很多作用，主要的三个作用是 ：保证进程之间的内存隔，保证进程有连续内存可用 ，扩展物理内存；页表这个机制说白了就是建立虚拟内存与物理内存之间的关系）



虚拟内存存在的意义之一，就是为了让程序认为自己有连续可用的内存；因为物理内存会在被使用的过程中逐渐变成“碎片”

这里我需要解释一下什么是“碎片”：如果进程都运行在物理内存上，假设我们的物理内存只有4个bit，分别记作0x00，0x01，0x02，0x03；在刚开机的时候，这四个bit都是可用的，随后发生了如下的过程：

1. 进程A占用了前2个bit：0x00 0x01 
2. 进程B占用了第3个bit：0x02
3. 进程A结束，释放了前2个bit
4. 进程C开始申请内存，发现可用内存是0x00 0x01 0x03

内存碎片就此产生了，原本连续的四个bit，被分割开来了；

这就产生了一个问题，如果进程C想要连续的3bits物理内存，就无法实现了，尽管空闲内存的总量是有3bits的，但是这些内存不连续；不连续的内存会有使用问题，比如数组如果存在不连续的内存里就无法正常使用；

那么怎么解决这个问题？操作系统会维护一个叫做页表的东西，这个表的作用是将不连续的物理内存映射到连续的虚拟内存中，这样在软件眼里，软件就有连续的内存可用了；



每个进程都会有一个属于自己的“page table（页表）”，页表将虚拟内存映射在物理内存上，如此一来，进程只能访问出现在自己页表里的物理内存；

操作系统会设置页表，使得每一个进程都有不重合的物理内存；这样进程就不能访问其他进程在使用的物理内存；



## system call

如果你理解了user mode和kernel mode，会发现一个问题，如果user mode和kernel mode之间的隔离是完全隔离的话，那么普通的用户程序就无法切换到kernel mode执行必要的操作，这当然是不合理的；我们需要一个user mode和kernel mode之间的桥梁；

实际上risc-v提供了一个叫ECALL的指令，使用ECALL并且传入一个参数（2，3，4...），这里的参数代表程序想要调用的system call；

当前我们使用C语言调用fork()这个系统调用的时候，实际上本质还不是调用内核里叫做fork的那段代码，而是调用了ECALL，通过ECALL调用内核里的syscall函数，syscall函数会检查你的参数是否正确，如果正确，再由syscall去调用内核里的fork函数；



## XV6系统对上述三者的实现

对xv6而言（实际上对unix乃至linux系统而言都差不多..）

xv6操作系统本身是运行在kernel mode下的，整个操作系统内核都运行在kernel mode下，这种设计方式被称为宏内核设计，因为这个内核很大，包含了硬件驱动，文件系统等等一系列的子部分，宏内核设计能够获得较好的性能；但是一大坨代码堆在一起也更容易产生bug

还有另一种系统设计方式，被称为微内核，这种设计方式致力于减少运行在kernel mode中代码，内核中也会保留一些模块，但更多的模块只是作为一个普通的用户程序运行在 user mode下；windows采用的就是微内核设计；这种设计的bug率理论上会小一些；但是由于一部分子系统位于user mode下，完成同样的功能需要更多的user/kernel切换开销；



代码分析：

在代码分析之前，你必须了解一个系统是怎样被编译的；最好了解一下C语言的编译-连接过程；最好了解一下GCC和GDB的使用；

### xv6系统编译过程的介绍

当我们在/xv6-riscv这个目录下运行make命令的时候，就是在编译XV6；

然而操作系统本身也是一个软件，只是这个软件规模较大，比较特殊而已；

Unix类系统基本上可以被看做是一个使用大量C语言和少量其他别的语言所编写的软件，因此C语言程序需要的汇编连接等步骤，unix系统也不能免俗；如果你有用过GCC那么应该对上述的过程有一定的理解，如果你没用过，可以看看我写的C语言笔记或者ARM系列的笔记；

总的来说，在make之后，就会生成可执行文件，使用make qemu命令就可以用qemu去运行这个操作系统，qemu的作用是模拟一个riscv架构的CPU；





### xv6系统的结构介绍



```shell
# xv6的结构已经相当简单，主要内容有三个文件夹
lifugui@lifugui_thinkpa:/mnt/d/6s081/xv6-riscv$ ls
LICENSE  Makefile  README  fs.img  kernel  mkfs  user
# 其中重要的三个文件夹是 kernel mkfs user
# 1. kernel文件夹，包含了所有内核文件，这个文件夹里的全部可执行文件都会被运行在kernel mode下；
lifugui@lifugui_thinkpa:/mnt/d/6s081/xv6-riscv$ ls kernel/
bio.c      exec.c   fs.o         log.d        plic.d     sleeplock.c  stat.h     sysfile.d     uart.c
bio.d      exec.d   kalloc.c     log.o        plic.o     sleeplock.d  string.c   sysfile.o     uart.d
bio.o      exec.o   kalloc.d     main.c       printf.c   sleeplock.h  string.d   sysproc.c     uart.o
buf.h      fcntl.h  kalloc.o     main.d       printf.d   sleeplock.o  string.o   sysproc.d     virtio.h
console.c  file.c   kernel       main.o       printf.o   spinlock.c   swtch.S    sysproc.o     virtio_disk.c
console.d  file.d   kernel.asm   memlayout.h  proc.c     spinlock.d   swtch.o    trampoline.S  virtio_disk.d
console.o  file.h   kernel.ld    param.h      proc.d     spinlock.h   syscall.c  trampoline.o  virtio_disk.o
defs.h     file.o   kernel.sym   pipe.c       proc.h     spinlock.o   syscall.d  trap.c        vm.c
elf.h      fs.c     kernelvec.S  pipe.d       proc.o     start.c      syscall.h  trap.d        vm.d
entry.S    fs.d     kernelvec.o  pipe.o       ramdisk.c  start.d      syscall.o  trap.o        vm.o
entry.o    fs.h     log.c        plic.c       riscv.h    start.o      sysfile.c  types.h

# 2. user文件夹，包含了用户软件的代码，可以看到我们很熟悉的一些命令，像ls，grep等，都在这里
# （没错哦，这些命令其实每个都是一个单独的软件...原则上说这些命令并没有绑死在操作系统上...）
lifugui@lifugui_thinkpa:/mnt/d/6s081/xv6-riscv$ ls user
_cat        _zombie       grep.asm   initcode      ln.sym     rm.c          ulib.d         usys.pl
_echo       cat.asm       grep.c     initcode.S    ls.asm     rm.d          ulib.o         wc.asm
_forktest   cat.c         grep.d     initcode.asm  ls.c       rm.o          umalloc.c      wc.c
_grep       cat.d         grep.o     initcode.d    ls.d       rm.sym        umalloc.d      wc.d
_grind      cat.o         grep.sym   initcode.o    ls.o       sh.asm        umalloc.o      wc.o
_init       cat.sym       grind.asm  initcode.out  ls.sym     sh.c          user.h         wc.sym
_kill       echo.asm      grind.c    kill.asm      mkdir.asm  sh.d          user.ld        zombie.asm
_ln         echo.c        grind.d    kill.c        mkdir.c    sh.o          usertests.asm  zombie.c
_ls         echo.d        grind.o    kill.d        mkdir.d    sh.sym        usertests.c    zombie.d
_mkdir      echo.o        grind.sym  kill.o        mkdir.o    stressfs.asm  usertests.d    zombie.o
_rm         echo.sym      init.asm   kill.sym      mkdir.sym  stressfs.c    usertests.o    zombie.sym
_sh         forktest.asm  init.c     ln.asm        printf.c   stressfs.d    usertests.sym
_stressfs   forktest.c    init.d     ln.c          printf.d   stressfs.o    usys.S
_usertests  forktest.d    init.o     ln.d          printf.o   stressfs.sym  usys.d
_wc         forktest.o    init.sym   ln.o          rm.asm     ulib.c        usys.o

# 3. mkfs，提供了一个空的文件镜像，我们存在这个文件夹下的文件就可以在xv6中找到；
```





### 操作系统的启动

接下来我会简略的描述，从内核被加载到shell被运行大致的流程：

**在开始了解操作系统的启动流程前，必须明确，qemu的功能是模拟了一个硬件，qemu提供的功能和一个4核riscv核心的主板是一样的**

```shell
# 使用gdb启动qemu，这样qemu就以gdb模式启动了，相当于一个gdb server
lifugui@lifugui_thinkpa:/mnt/d/6s081/xv6-riscv$ make qemu-gdb
*** Now run 'gdb' in another window.
qemu-system-riscv64 -machine virt -bios none -kernel kernel/kernel -m 128M -smp 3 -nographic -global virtio-mmio.force-legacy=false -drive file=fs.img,if=none,format=raw,id=x0 -device virtio-blk-device,drive=x0,bus=virtio-mmio-bus.0 -S -gdb tcp::26000

```

然后在相同路径下启动gdb，就可以调试这个xv6系统了

```shell
lifugui@lifugui_thinkpa:/mnt/d/6s081/xv6-riscv$ riscv64-unknown-elf-gdb
GNU gdb (GDB) 13.1
Copyright (C) 2023 Free Software Foundation, Inc.
License GPLv3+: GNU GPL version 3 or later <http://gnu.org/licenses/gpl.html>
This is free software: you are free to change and redistribute it.
There is NO WARRANTY, to the extent permitted by law.
Type "show copying" and "show warranty" for details.
This GDB was configured as "--host=x86_64-pc-linux-gnu --target=riscv64-unknown-elf".
Type "show configuration" for configuration details.
For bug reporting instructions, please see:
<https://www.gnu.org/software/gdb/bugs/>.
Find the GDB manual and other documentation resources online at:
    <http://www.gnu.org/software/gdb/documentation/>.

For help, type "help".
Type "apropos word" to search for commands related to "word".
The target architecture is set to "riscv:rv64".
warning: No executable has been specified and target does not support
determining executable automatically.  Try using the "file" command.
0x0000000000001000 in ?? ()
(gdb) 
# 后面会逐渐涉及到gdb的一些使用，等用到了再说
```



在编译xv6的时候，会产生一些asm文件，这些文件是软件的汇编语言版本，从这里开始我们就开始正式进入xv6的代码部分；

从/kernel/kernel.asm开始

```assembly
kernel/kernel:     file format elf64-littleriscv


Disassembly of section .text:

0000000080000000 <_entry>:
    80000000:   00009117                auipc   sp,0x9
    80000004:   a1010113                addi    sp,sp,-1520 # 80008a10 <stack0>
    80000008:   6505                    lui     a0,0x1
    8000000a:   f14025f3                csrr    a1,mhartid
    8000000e:   0585                    addi    a1,a1,1
    80000010:   02b50533                mul     a0,a0,a1
    80000014:   912a                    add     sp,sp,a0
    80000016:   078000ef                jal     ra,8000008e <start>

000000008000001a <spin>:
    8000001a:   a001                    j       8000001a <spin>
# 后面还有很多...暂时掠过，以这一小段作为样本简单解释一下asm文件怎么看
# 0000000080000000 <_entry>: 这里的_entry 是"段名"；段名类似于函数名，用户可以自己定义，但是要受到一些约束；总的来说段名是为了给人提供方便的，在后面的使用中详细你会逐渐体会到；
#	80000000:   00009117                auipc   sp,0x9
#	80000000是内存地址
#	00009117是机器码
#	auipc是指令（和汇编中的add，sub等等指令是一类东西）
#	sp，0x9是寄存器和操作数
#	这行代码合起来的意思是，在内存 80000000 里存着00009117，而00009117是一条指令，这条指令是auipc，参数是sp和0x9
```

使用gdb查看最开始的样子：

```assembly
0x0000000000001000 in ?? ()
(gdb) b _entry
# 注： b _entry表示在_entry处设置断点
Breakpoint 1 at 0x8000000a
(gdb) c
# c表示继续运行
Continuing.
[Switching to Thread 1.2]

Thread 2 hit Breakpoint 1, 0x000000008000000a in _entry ()
=> 0x000000008000000a <_entry+10>:      f14025f3                csrr    a1,mhartid
# 从这里可以看到断点停在了地址0x0000 0000 8000 000a
```

这里有一些需要解释的地方：

1. 为什么是从\_entry开始的？ 实际上XV6本身作为一个C语言编写的程序，逻辑上程序的入口是main函数，不过如果你真的把C语言程序编译后的机器码拿出来分析，会发现在main函数之前还有一小段别的代码，在研究C语言编译的过程中，我发现C语言的真正开端是一个叫做\_start的段，至少在linux中是这样的；或许这里的_entry起到的也是同样的作用吧....这个问题需要研究一下；
2. 为什么开始的地址是8000 0000而不是0000 0000？ 因为我们只看操作系统，实际上计算机启动的时候，最先运行的是一个引导程序，这个引导程序才是从0x0000 0000  0000 0000开始运行的（不过也不尽然...boot部分和硬件是息息相关的，不同的核心会有一些差异，不过总体而言大差不差），负责做一些硬件上的初始化工作，对这个有兴趣的建议看看uboot；
3. 从8000 0000 开始就进入操作系统了吗？是的，从8000 0000 开始就已经正式进入操作系统了，不过在这里有很多东西都还没有被加载或者被初始化，还没有内存页，隔离性等东西；
4. 此时这些代码运行在什么模式下？ 运行在M mode下， 这是riscv的机器模式，是riscv中权限最高的模式，这个阶段不会持续太久，xv6很快会跳转到kernel mode下去运行，这个过程发生在main()中；

在课程中，接下来使用了gdb的layout split模式，这种模式可以让我们同时看到gdb信息，汇编信息，原始代码信息；

让我们来看一下main函数，在这个函数中，程序会进行很多初始化工作，xv6的第一个系统调用也发生在这个函数里：

![image-20240206185745925](.\图片\image-20240206185745925.png)

可以看到main做的第一件事是初始化console，然后初始化printf，然后就开始打印信息了，此时可以在gdb中使用"n"进行单步执行，观察这个过程

![image-20240206191018254](.\图片\image-20240206191018254.png)

![image-20240206191045667](.\图片\image-20240206191045667.png)

可以看到xv6输出了“xv6 kernel is booting”

接下来的代码，像kinit，kvminit等也都是初始化代码，下面是main的完整代码

```c
// start() jumps here in supervisor mode on all CPUs.
// 这里的注释说明了，任何型号的CPU都会通过start()以supervisor mode权限跳转到这里执行
void
main()
{
  if(cpuid() == 0){
    consoleinit();
    printfinit();
    printf("\n");
    printf("xv6 kernel is booting\n");
    printf("\n");
    kinit();         // physical page allocator
    kvminit();       // create kernel page table
    kvminithart();   // turn on paging
    procinit();      // process table
    trapinit();      // trap vectors
    trapinithart();  // install kernel trap vector
    plicinit();      // set up interrupt controller
    plicinithart();  // ask PLIC for device interrupts
    binit();         // buffer cache
    iinit();         // inode table
    fileinit();      // file table
    virtio_disk_init(); // emulated hard disk
    userinit();      // first user process
    __sync_synchronize();
    started = 1;
  } else {
    while(started == 0)
      ;
    __sync_synchronize();
    printf("hart %d starting\n", cpuid());
    kvminithart();    // turn on paging
    trapinithart();   // install kernel trap vector
    plicinithart();   // ask PLIC for device interrupts
  }
```

这些代码里有一个函数需要特别关注一下，userinit函数，这个函数会开启第一个用户进程；

使用gdb命令s，可以进入这个函数（gdb中 s和n都是单步执行，s会进入函数，n不会进入函数）

userinit位于kernel/proc.c中；

```c
uchar initcode[] = {
  0x17, 0x05, 0x00, 0x00, 0x13, 0x05, 0x45, 0x02,
  0x97, 0x05, 0x00, 0x00, 0x93, 0x85, 0x35, 0x02,
  0x93, 0x08, 0x70, 0x00, 0x73, 0x00, 0x00, 0x00,
  0x93, 0x08, 0x20, 0x00, 0x73, 0x00, 0x00, 0x00,
  0xef, 0xf0, 0x9f, 0xff, 0x2f, 0x69, 0x6e, 0x69,
  0x74, 0x00, 0x00, 0x24, 0x00, 0x00, 0x00, 0x00,
  0x00, 0x00, 0x00, 0x00
};

// Set up first user process.
void
userinit(void)
{
  struct proc *p;

  p = allocproc();
  initproc = p;

  // allocate one user page and copy initcode's instructions
  // and data into it.
  uvmfirst(p->pagetable, initcode, sizeof(initcode));//这行是这个函数的重点，这行代码会设置一个内存页，然后把initcode加载到这个内存页里执行
  p->sz = PGSIZE;

  // prepare for the very first "return" from kernel to user.
  p->trapframe->epc = 0;      // user program counter
  p->trapframe->sp = PGSIZE;  // user stack pointer

  safestrcpy(p->name, "initcode", sizeof(p->name));
  p->cwd = namei("/");

  p->state = RUNNABLE;

  release(&p->lock);
}
```

**详细分析一下userinit中的initcode**

```asm
/* uchar initcode[] = {
  0x17, 0x05, 0x00, 0x00, 0x13, 0x05, 0x45, 0x02,
  0x97, 0x05, 0x00, 0x00, 0x93, 0x85, 0x35, 0x02,
  0x93, 0x08, 0x70, 0x00, 0x73, 0x00, 0x00, 0x00,
  0x93, 0x08, 0x20, 0x00, 0x73, 0x00, 0x00, 0x00,
  0xef, 0xf0, 0x9f, 0xff, 0x2f, 0x69, 0x6e, 0x69,
  0x74, 0x00, 0x00, 0x24, 0x00, 0x00, 0x00, 0x00,
  0x00, 0x00, 0x00, 0x00
};*/
# 这段代码实际上是一段机器码，这段机器码是/user/initcode.S
# 通过查看/user/initcode.S对应的asm文件可以确认这点
user/initcode.o:     file format elf64-littleriscv


Disassembly of section .text:

0000000000000000 <start>:
#include "syscall.h"

# exec(init, argv)
.globl start
start:
        la a0, init
   0:   00000517                auipc   a0,0x0
   4:   00050513                mv      a0,a0
        la a1, argv
   8:   00000597                auipc   a1,0x0
   c:   00058593                mv      a1,a1
        li a7, SYS_exec
  10:   00700893                li      a7,7
        ecall
  14:   00000073                ecall

0000000000000018 <exit>:

# for(;;) exit();
exit:
        li a7, SYS_exit
  18:   00200893                li      a7,2
        ecall
  1c:   00000073                ecall
        jal exit
  20:   ff9ff0ef                jal     ra,18 <exit>

0000000000000024 <init>:
  24:   696e692f                0x696e692f
  28:   0074                    addi    a3,sp,12
        ...

000000000000002b <argv>:
        ...

```

仔细对照一下，是不是一毛一样？

我们来分析一下`initcode.S`

```assembly
0000000000000000 <start>:
#include "syscall.h"

# exec(init, argv)
.globl start
start:
        la a0, init
   0:   00000517                auipc   a0,0x0
   4:   00050513                mv      a0,a0
        la a1, argv
   8:   00000597                auipc   a1,0x0
   c:   00058593                mv      a1,a1
        li a7, SYS_exec
  10:   00700893                li      a7,7
        ecall
  14:   00000073                ecall

# 我们只取前四行代码
# la a0, init
# la a1, argv
# li a7, SYS_exec
# ecall
#
# 请注意！！！ 在执行这几行代码的时候，cpu是运行在user mode下的
# 这几行代码的含义是
# 将init中的地址加载到a0寄存器
# 将argv中的地址加载到a1寄存器
# 将SYS_exec（值为7）的值加载到a7寄存器
# 调用ecall
# 
# 还记的ecall的机制吗？ecall会带着7这个参数进入内核，执行内核中的功能
# 这里可以看一看syscall.h文件，这个文件里定义了全部的系统调用编号
#define SYS_fork    1
#define SYS_exit    2
#define SYS_wait    3
#define SYS_pipe    4
#define SYS_read    5
#define SYS_kill    6
#define SYS_exec    7  7是SYS_exec
#...
```

（注： 这里省略了很多细节，比如为什么进入main的时候还是运行在kernel mode下的，执行initcode的时候就变成了user mode，这些细节问题会在后续的笔记中揭晓）

我们可以在`/kernel/sysfile.c`中找到`sys_exec`的正体，不过目前他还不是重点，我们会在后续的学习中学到；

**总之，initcode()函数在通过sys_exec调用一个叫做init的东西，这个init是另一个程序，这个init实际上就是/user/init.c程序，这个程序会设置好console，执行fork，进行一些其他的工作，然后启动shell**

到此，我们就可以用到shell了



**看完这里之后可以做第一个lab**





## XV6的Makefile



### 原始Makefile概览

```makefile

# To compile and run with a lab solution, set the lab name in lab.mk
# (e.g., LB=util).  Run make grade to test solution with the lab's
# grade script (e.g., grade-lab-util).

-include conf/lab.mk

K=kernel
U=user

OBJS = \		# OBJS是kernel代码的.o文件
  $K/entry.o \
  $K/start.o \
  $K/console.o \
  $K/printf.o \
  $K/uart.o \
  $K/kalloc.o \
  $K/spinlock.o \
  $K/string.o \
  $K/main.o \
  $K/vm.o \
  $K/proc.o \
  $K/swtch.o \
  $K/trampoline.o \
  $K/trap.o \
  $K/syscall.o \
  $K/sysproc.o \
  $K/bio.o \
  $K/fs.o \
  $K/log.o \
  $K/sleeplock.o \
  $K/file.o \
  $K/pipe.o \
  $K/exec.o \
  $K/sysfile.o \
  $K/kernelvec.o \
  $K/plic.o \
  $K/virtio_disk.o \

ifeq ($(LAB),pgtbl)		# ifeq都是用来控制lab的，不同的lab相较原版xv6会缺少一些功能，让学生自己实现
OBJS += $K/vmcopyin.o
endif

# riscv64-unknown-elf- or riscv64-linux-gnu-
# perhaps in /opt/riscv/bin
#TOOLPREFIX = 

# Try to infer the correct TOOLPREFIX if not set
# 设置工具链
ifndef TOOLPREFIX
TOOLPREFIX := $(shell if riscv64-unknown-elf-objdump -i 2>&1 | grep 'elf64-big' >/dev/null 2>&1; \
	then echo 'riscv64-unknown-elf-'; \
	elif riscv64-linux-gnu-objdump -i 2>&1 | grep 'elf64-big' >/dev/null 2>&1; \
	then echo 'riscv64-linux-gnu-'; \
	elif riscv64-unknown-linux-gnu-objdump -i 2>&1 | grep 'elf64-big' >/dev/null 2>&1; \
	then echo 'riscv64-unknown-linux-gnu-'; \
	else echo "***" 1>&2; \
	echo "*** Error: Couldn't find a riscv64 version of GCC/binutils." 1>&2; \
	echo "*** To turn off this error, run 'gmake TOOLPREFIX= ...'." 1>&2; \
	echo "***" 1>&2; exit 1; fi)
endif

QEMU = qemu-system-riscv64

CC = $(TOOLPREFIX)gcc			# 设定 编译器 为 gcc
AS = $(TOOLPREFIX)gas			# 设定 汇编器 为 gas
LD = $(TOOLPREFIX)ld			# 设定 链接器 为 ld
OBJCOPY = $(TOOLPREFIX)objcopy	# 设定 objcopy
OBJDUMP = $(TOOLPREFIX)objdump	# 设定 objdump

CFLAGS = -Wall -Werror -O -fno-omit-frame-pointer -ggdb

ifdef LAB
LABUPPER = $(shell echo $(LAB) | tr a-z A-Z)
CFLAGS += -DSOL_$(LABUPPER)
endif

CFLAGS += -MD
CFLAGS += -mcmodel=medany
CFLAGS += -ffreestanding -fno-common -nostdlib -mno-relax
CFLAGS += -I.
CFLAGS += $(shell $(CC) -fno-stack-protector -E -x c /dev/null >/dev/null 2>&1 && echo -fno-stack-protector)

# Disable PIE when possible (for Ubuntu 16.10 toolchain)
ifneq ($(shell $(CC) -dumpspecs 2>/dev/null | grep -e '[^f]no-pie'),)
CFLAGS += -fno-pie -no-pie
endif
ifneq ($(shell $(CC) -dumpspecs 2>/dev/null | grep -e '[^f]nopie'),)
CFLAGS += -fno-pie -nopie
endif

LDFLAGS = -z max-page-size=4096

$K/kernel: $(OBJS) $K/kernel.ld $U/initcode
	$(LD) $(LDFLAGS) -T $K/kernel.ld -o $K/kernel $(OBJS) 
	$(OBJDUMP) -S $K/kernel > $K/kernel.asm
	$(OBJDUMP) -t $K/kernel | sed '1,/SYMBOL TABLE/d; s/ .* / /; /^$$/d' > $K/kernel.sym

$U/initcode: $U/initcode.S
	$(CC) $(CFLAGS) -march=rv64g -nostdinc -I. -Ikernel -c $U/initcode.S -o $U/initcode.o
	$(LD) $(LDFLAGS) -N -e start -Ttext 0 -o $U/initcode.out $U/initcode.o
	$(OBJCOPY) -S -O binary $U/initcode.out $U/initcode
	$(OBJDUMP) -S $U/initcode.o > $U/initcode.asm

tags: $(OBJS) _init
	etags *.S *.c

ULIB = $U/ulib.o $U/usys.o $U/printf.o $U/umalloc.o

_%: %.o $(ULIB)
	$(LD) $(LDFLAGS) -N -e main -Ttext 0 -o $@ $^
	$(OBJDUMP) -S $@ > $*.asm
	$(OBJDUMP) -t $@ | sed '1,/SYMBOL TABLE/d; s/ .* / /; /^$$/d' > $*.sym

$U/usys.S : $U/usys.pl
	perl $U/usys.pl > $U/usys.S

$U/usys.o : $U/usys.S
	$(CC) $(CFLAGS) -c -o $U/usys.o $U/usys.S

$U/_forktest: $U/forktest.o $(ULIB)
	# forktest has less library code linked in - needs to be small
	# in order to be able to max out the proc table.
	$(LD) $(LDFLAGS) -N -e main -Ttext 0 -o $U/_forktest $U/forktest.o $U/ulib.o $U/usys.o
	$(OBJDUMP) -S $U/_forktest > $U/forktest.asm

mkfs/mkfs: mkfs/mkfs.c $K/fs.h $K/param.h
	gcc -Werror -Wall -I. -o mkfs/mkfs mkfs/mkfs.c

# Prevent deletion of intermediate files, e.g. cat.o, after first build, so
# that disk image changes after first build are persistent until clean.  More
# details:
# http://www.gnu.org/software/make/manual/html_node/Chained-Rules.html
.PRECIOUS: %.o

UPROGS=\
	$U/_cat\
	$U/_echo\
	$U/_forktest\
	$U/_grep\
	$U/_init\
	$U/_kill\
	$U/_ln\
	$U/_ls\
	$U/_mkdir\
	$U/_rm\
	$U/_sh\
	$U/_stressfs\
	$U/_usertests\
	$U/_grind\
	$U/_wc\
	$U/_zombie\
	$U/_trace


ifeq ($(LAB),trap)
UPROGS += \
	$U/_call\
	$U/_alarmtest
endif

ifeq ($(LAB),lazy)
UPROGS += \
	$U/_lazytests
endif

ifeq ($(LAB),cow)
UPROGS += \
	$U/_cowtest
endif

UEXTRA=
ifeq ($(LAB),util)
	UEXTRA += user/xargstest.sh
endif

fs.img: mkfs/mkfs README $(UEXTRA) $(UPROGS)
	mkfs/mkfs fs.img README $(UEXTRA) $(UPROGS)

-include kernel/*.d user/*.d

clean: 
	rm -f *.tex *.dvi *.idx *.aux *.log *.ind *.ilg \
	*/*.o */*.d */*.asm */*.sym \
	$U/initcode $U/initcode.out $K/kernel fs.img \
	mkfs/mkfs .gdbinit \
        $U/usys.S \
	$(UPROGS)

# try to generate a unique GDB port
GDBPORT = $(shell expr `id -u` % 5000 + 25000)
# QEMU's gdb stub command line changed in 0.11
QEMUGDB = $(shell if $(QEMU) -help | grep -q '^-gdb'; \
	then echo "-gdb tcp::$(GDBPORT)"; \
	else echo "-s -p $(GDBPORT)"; fi)
ifndef CPUS
CPUS := 3
endif

QEMUOPTS = -machine virt -bios none -kernel $K/kernel -m 128M -smp $(CPUS) -nographic
QEMUOPTS += -drive file=fs.img,if=none,format=raw,id=x0
QEMUOPTS += -device virtio-blk-device,drive=x0,bus=virtio-mmio-bus.0

qemu: $K/kernel fs.img
	$(QEMU) $(QEMUOPTS)

.gdbinit: .gdbinit.tmpl-riscv
	sed "s/:1234/:$(GDBPORT)/" < $^ > $@

qemu-gdb: $K/kernel .gdbinit fs.img
	@echo "*** Now run 'gdb' in another window." 1>&2
	$(QEMU) $(QEMUOPTS) -S $(QEMUGDB)

##
##  FOR testing lab grading script
##

ifneq ($(V),@)
GRADEFLAGS += -v
endif

print-gdbport:
	@echo $(GDBPORT)

grade:
	@echo $(MAKE) clean
	@$(MAKE) clean || \
          (echo "'make clean' failed.  HINT: Do you have another running instance of xv6?" && exit 1)
	./grade-lab-$(LAB) $(GRADEFLAGS)

##
## FOR web handin
##


WEBSUB := https://6828.scripts.mit.edu/2020/handin.py

handin: tarball-pref myapi.key
	@SUF=$(LAB); \
	curl -f -F file=@lab-$$SUF-handin.tar.gz -F key=\<myapi.key $(WEBSUB)/upload \
	    > /dev/null || { \
		echo ; \
		echo Submit seems to have failed.; \
		echo Please go to $(WEBSUB)/ and upload the tarball manually.; }

handin-check:
	@if ! test -d .git; then \
		echo No .git directory, is this a git repository?; \
		false; \
	fi
	@if test "$$(git symbolic-ref HEAD)" != refs/heads/$(LAB); then \
		git branch; \
		read -p "You are not on the $(LAB) branch.  Hand-in the current branch? [y/N] " r; \
		test "$$r" = y; \
	fi
	@if ! git diff-files --quiet || ! git diff-index --quiet --cached HEAD; then \
		git status -s; \
		echo; \
		echo "You have uncomitted changes.  Please commit or stash them."; \
		false; \
	fi
	@if test -n "`git status -s`"; then \
		git status -s; \
		read -p "Untracked files will not be handed in.  Continue? [y/N] " r; \
		test "$$r" = y; \
	fi

UPSTREAM := $(shell git remote -v | grep -m 1 "xv6-labs-2020" | awk '{split($$0,a," "); print a[1]}')

tarball: handin-check
	git archive --format=tar HEAD | gzip > lab-$(LAB)-handin.tar.gz

tarball-pref: handin-check
	@SUF=$(LAB); \
	git archive --format=tar HEAD > lab-$$SUF-handin.tar; \
	git diff $(UPSTREAM)/$(LAB) > /tmp/lab-$$SUF-diff.patch; \
	tar -rf lab-$$SUF-handin.tar /tmp/lab-$$SUF-diff.patch; \
	gzip -c lab-$$SUF-handin.tar > lab-$$SUF-handin.tar.gz; \
	rm lab-$$SUF-handin.tar; \
	rm /tmp/lab-$$SUF-diff.patch; \

myapi.key:
	@echo Get an API key for yourself by visiting $(WEBSUB)/
	@read -p "Please enter your API key: " k; \
	if test `echo "$$k" |tr -d '\n' |wc -c` = 32 ; then \
		TF=`mktemp -t tmp.XXXXXX`; \
		if test "x$$TF" != "x" ; then \
			echo "$$k" |tr -d '\n' > $$TF; \
			mv -f $$TF $@; \
		else \
			echo mktemp failed; \
			false; \
		fi; \
	else \
		echo Bad API key: $$k; \
		echo An API key should be 32 characters long.; \
		false; \
	fi;


.PHONY: handin tarball tarball-pref clean grade handin-check

```

### 分析：kernel的build

kernel的构建主要由以下的代码完成

```makefile
K=kernel
#...
OBJS = \
  $K/entry.o \
  $K/start.o \
  $K/console.o \
  $K/printf.o \
  $K/uart.o \
  $K/kalloc.o \
  $K/spinlock.o \
  $K/string.o \
  $K/main.o \
  $K/vm.o \
  $K/proc.o \
  $K/swtch.o \
  $K/trampoline.o \
  $K/trap.o \
  $K/syscall.o \
  $K/sysproc.o \
  $K/bio.o \
  $K/fs.o \
  $K/log.o \
  $K/sleeplock.o \
  $K/file.o \
  $K/pipe.o \
  $K/exec.o \
  $K/sysfile.o \
  $K/kernelvec.o \
  $K/plic.o \
  $K/virtio_disk.o \
#...
$K/kernel: $(OBJS) $K/kernel.ld $U/initcode
        $(LD) $(LDFLAGS) -T $K/kernel.ld -o $K/kernel $(OBJS)
        $(OBJDUMP) -S $K/kernel > $K/kernel.asm
        $(OBJDUMP) -t $K/kernel | sed '1,/SYMBOL TABLE/d; s/ .* / /; /^$$/d' > $K/kernel.sym

$U/initcode: $U/initcode.S
        $(CC) $(CFLAGS) -march=rv64g -nostdinc -I. -Ikernel -c $U/initcode.S -o $U/initcode.o
        $(LD) $(LDFLAGS) -N -e start -Ttext 0 -o $U/initcode.out $U/initcode.o
        $(OBJCOPY) -S -O binary $U/initcode.out $U/initcode
        $(OBJDUMP) -S $U/initcode.o > $U/initcode.asm
```

`kernel/kernel`需要由 `OBJS`，`kernel/kernel.ld`，`user\initcode`构成；

1. 其中`kernel/kernel.ld`是提前写好的，不需要考虑；

2. `initcode`这个东西如果你还记得之前xv6是如何从boot到启动第一个process的话，应该知道，有一段被存在数组里的汇编程序，用于启动第一个process，这段数组就是这里来的；

3. 在`kernel\kernel`的依赖中，`$(OBJS)`是一些`.o`文件，但是整个Makefile文件中，并没有目标为`.o`文件的规则，但是通过查看make的log，会发现这些`.o`文件确实是被构建了的：

   ```shell
   #.. 在构建kernel/kernel的过程中，需要一个叫做 kernel/start.o的文件，但是这个文件不存在
   File 'kernel/start.o' does not exist.
       Must remake target 'kernel/start.o'.
   riscv64-unknown-elf-gcc -Wall -Werror -O -fno-omit-frame-pointer -ggdb -DSOL_SYSCALL -MD -mcmodel=medany -ffreestanding -fno-common -nostdlib -mno-relax -I. -fno-stack-protector -fno-pie -no-pie   -c -o kernel/start.o kernel/start.c#这一句代码构建了kernel/start.o文件，但是，这个规则我们并没有写啊？
   ```

   这里涉及到Makefile的隐式规则，当缺少依赖，但是makefile中又没有明确写明依赖的生成方式时，make会进行一个自动猜测，利用同名文件(比如针对`start.o`会自动尝试使用`start.c`去生成)尝试生成，这里的这些`.o`文件就是利用隐式规则生成的；隐式规则可以让makefile更简练，但是这种规则也可能会导致make失败；

### fs.img的build

```shell
# ...
File 'user/initcode' does not exist.
    Must remake target 'user/initcode'.
riscv64-unknown-elf-gcc -Wall -Werror -O -fno-omit-frame-pointer -ggdb -DSOL_SYSCALL -MD -mcmodel=medany -ffreestanding -fno-common -nostdlib -mno-relax -I. -fno-stack-protector -fno-pie -no-pie -march=rv64g -nostdinc -I. -Ikernel -c user/initcode.S -o user/initcode.o
   File 'fs.img' does not exist.
     File 'mkfs/mkfs' does not exist.
    Must remake target 'mkfs/mkfs'.
gcc -Werror -Wall -I. -o mkfs/mkfs mkfs/mkfs.c
# ...
```

通过make的log，可以看到，当`user\initcode`生成完毕之后，make开始继续生成`fs.img`；这是因为**我们使用的命令是 make qemu；这是一个伪目标**；如下：

```makefile
qemu: $K/kernel fs.img
        $(QEMU) $(QEMUOPTS)
```

可以看到确实只有两个依赖`kernel\kernle`和`fs.img`

`fs.img`的构建规则如下：

```makefile
fs.img: mkfs/mkfs README $(UEXTRA) $(UPROGS)
	mkfs/mkfs fs.img README $(UEXTRA) $(UPROGS)
# 其中 $(UPROGS)如下
UPROGS=\
	$U/_cat\
	$U/_echo\
	$U/_forktest\
	$U/_grep\
	$U/_init\
	$U/_kill\
	$U/_ln\
	$U/_ls\
	$U/_mkdir\
	$U/_rm\
	$U/_sh\
	$U/_stressfs\
	$U/_usertests\
	$U/_grind\
	$U/_wc\
	$U/_zombie\
	$U/_trace

```

构建时会发现`user\_ls`等都不存在，make会自上而下寻找适合`user\_cat`的构建规则，其规则如下：

```makefile
ULIB = $U/ulib.o $U/usys.o $U/printf.o $U/umalloc.o

_%: %.o $(ULIB)
	$(LD) $(LDFLAGS) -N -e main -Ttext 0 -o $@ $^
	$(OBJDUMP) -S $@ > $*.asm
	$(OBJDUMP) -t $@ | sed '1,/SYMBOL TABLE/d; s/ .* / /; /^$$/d' > $*.sym
```

这里需要注意的是，在进行链接的时候`usys.o`是参与了链接的；

`usys`这个文件中相当于实现了用户空间的系统调用，关于这点会在后面关于系统调用的实现详细展开；



## 关于系统调用的实现

系统调用是如何被调用的，以及我们要如何添加一个自己编写的系统调用；

### 理解kernel和fs.img

qemu在启动xv6的时候，依赖两个东西，一个是kernel，一个是`fs.img`；前者自然就是内核，但是后者，后者是文件镜像；

系统的启动过程可以被简单的描述为，把kernel加载上，然后把文件系统挂载上；然后就启动完成了；

我们在xv6中使用的cat，ls，echo这些命令，并不是kernel的一部分，这些命令是属于`fs.img`的；



### usys.pl

在`user\`下面，我们可以找到一个`usys.pl`文件，这是一个`perl`语言编写的文件；如果查看Makefile会发现，make之后这个`usys.pl`会被编译成`usys.S`文件

```makefile
$U/usys.S : $U/usys.pl
        perl $U/usys.pl > $U/usys.S
```

这里就以`usys.pl`介绍一下`perl`的语法，perl是脚本语言；

```perl
#!/usr/bin/perl -w

# Generate usys.S, the stubs for syscalls.

print "# generated by usys.pl - do not edit\n";

print "#include \"kernel/syscall.h\"\n";

sub entry {
    my $name = shift; # shift的作用是移出参数数组的第一个元素，并且返回
    # 例如：当下文中使用entry("fork")时候，会把"fork"这个参数放入参数数组；
    # 在经过shift处理后，参数数组中的"fork"会被移除；$name会被赋值"fork"
    print ".global $name\n";
    print "${name}:\n";
    print " li a7, SYS_${name}\n";
    print " ecall\n";
    print " ret\n";
}

entry("fork");
#...
entry("uptime");
```

usys.pl会被转化为一个usys.S的文件，这个usys.S是个汇编文件



```assembly
# generated by usys.pl - do not edit
#include "kernel/syscall.h"
.global fork
fork:
 li a7, SYS_fork
 ecall
 ret
.global exit
exit:
 li a7, SYS_exit
 ecall
 ret
.global wait
wait:
 li a7, SYS_wait
 ecall
 ret
#...后面都是类似于这样的汇编命令
```

找一个例子：`echo.c`中的`exit()`是一个系统调用

```c
// user/echo.c
#include "kernel/types.h"
#include "kernel/stat.h"
#include "user/user.h"

int
main(int argc, char *argv[])
{
  int i;

  for(i = 1; i < argc; i++){
    write(1, argv[i], strlen(argv[i]));
    if(i + 1 < argc){
      write(1, " ", 1);
    } else {
      write(1, "\n", 1);
    }
  }
  exit(0);// 探究一下 exit()的执行过程
}
```

### 系统调用的声明和定义

`exit()`声明在`user/user.h`中，系统调用在user mode下必须有一个声明，用户进程需要通过这个声明去调用程序；

`exit()`的实现是一段汇编代码，**C语言是可以调用到汇编语言的**

看一看Makefile中记录的xv6的编译流程

```makefile
ULIB = $U/ulib.o $U/usys.o $U/printf.o $U/umalloc.o

_%: %.o $(ULIB)
	$(LD) $(LDFLAGS) -N -e main -Ttext 0 -o $@ $^
	$(OBJDUMP) -S $@ > $*.asm
	$(OBJDUMP) -t $@ | sed '1,/SYMBOL TABLE/d; s/ .* / /; /^$$/d' > $*.sym

$U/usys.S : $U/usys.pl
	perl $U/usys.pl > $U/usys.S

$U/usys.o : $U/usys.S
	$(CC) $(CFLAGS) -c -o $U/usys.o $U/usys.S
#...
UPROGS=\
	$U/_cat\
	$U/_echo\
	$U/_forktest\
	$U/_grep\
	$U/_init\
	$U/_kill\
	$U/_ln\
	$U/_ls\
	$U/_mkdir\
	$U/_rm\
	$U/_sh\
	$U/_stressfs\
	$U/_usertests\
	$U/_grind\
	$U/_wc\
	$U/_zombie\
	$U/_trace
#...
# 关于fs.img的构建，需要注意以下这里使用了makeifle的隐式规则，$(UPROGS)中的生成规则没有被明确的写出来，由makefile自己猜测生成；
fs.img: mkfs/mkfs README $(UEXTRA) $(UPROGS)
        mkfs/mkfs fs.img README $(UEXTRA) $(UPROGS)
#...
qemu: $K/kernel fs.img
	$(QEMU) $(QEMUOPTS)
```

**所以：在用户空间，系统调用的声明在`user\user.h`，实现在`usys.pl`中， 实现的本质是使用perl脚本生成相对应的汇编语言，然后在make的过程中链接 **



### 系统调用过程分析

仍旧以exit(0)这个系统调用为例子分析：

#### user/user.h

```c
struct stat;
struct rtcdate;

// system calls
int fork(void);
int exit(int) __attribute__((noreturn));
//.....
```



#### user/usys

```assembly
# user/usys.S

#...
.global exit
exit:
 li a7, SYS_exit
 ecall
 ret
#...
```

这里将`SYS_exit`的值放到`a7`寄存器中，然后调用`ecall`，系统进入`kernel mode`



#### kernel/syscall.h

`SYS_exit`是定义在`kernel/syscall.h`中的，是系统调用编号

```c
// System call numbers
#define SYS_fork    1
#define SYS_exit    2
#define SYS_wait    3
#define SYS_pipe    4
#define SYS_read    5
#define SYS_kill    6
#define SYS_exec    7
#define SYS_fstat   8
#define SYS_chdir   9
#define SYS_dup    10
#define SYS_getpid 11
#define SYS_sbrk   12
#define SYS_sleep  13
#define SYS_uptime 14
#define SYS_open   15
#define SYS_write  16
#define SYS_mknod  17
#define SYS_unlink 18
#define SYS_link   19
#define SYS_mkdir  20
#define SYS_close  21
#define SYS_trace  22
```

#### kernel/syscall.c

```c
#include "types.h"
#include "param.h"
#include "memlayout.h"
#include "riscv.h"
#include "spinlock.h"
#include "proc.h"
#include "syscall.h"
#include "defs.h"

//....

//....
extern uint64 sys_exec(void); //表明这个函数是一个定义在别的地方的函数
extern uint64 sys_exit(void);
//....

static uint64 (*syscalls[])(void) = {
[SYS_fork]    sys_fork,
[SYS_exit]    sys_exit,
//...
};

char * syscalls_name[]=
{
[SYS_fork]    "fork",
[SYS_exit]    "exit",
//.....
};

void
syscall(void)
{
  int num;
  struct proc *p = myproc();

  num = p->trapframe->a7; //从a7中取出系统调用号，这样就知道我们使用的是哪个系统调用
  if(num > 0 && num < NELEM(syscalls) && syscalls[num]) {
    // Use num to lookup the system call function for num, call it,
    // and store its return value in p->trapframe->a0
    p->trapframe->a0 = syscalls[num]();
  } else {
    printf("%d %s: unknown sys call %d\n",
            p->pid, p->name, num);
    p->trapframe->a0 = -1;
  }
}
```

`ecall`会在历经一系列软件硬件处理之后到达`syscall()`函数；`syscall()`会使用`a7`寄存器中的系统调用号，在`syscalls[]`数组中查找对应的系统调用函数；在exit()这个例子中，我们会调用`sys_exit()`函数；这个函数的定义位于`kernel/sysproc.c`中



#### kernel/sysproc.c

```c
#include "types.h"
#include "riscv.h"
#include "defs.h"
#include "date.h"
#include "param.h"
#include "memlayout.h"
#include "spinlock.h"
#include "proc.h"

uint64
sys_exit(void)
{
  int n;
  if(argint(0, &n) < 0)
    return -1;
  exit(n);
  return 0;  // not reached
}
//......

```



执行结束



















